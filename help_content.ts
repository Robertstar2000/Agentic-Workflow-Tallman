/**
 * This file stores the content of help.md as a string to be easily imported
 * into the HelpModal component without needing a file loader.
 */
export const helpContent = `
### Welcome to the AI Workflow System!

This guide will walk you through setting up and using the platform to automate complex tasks.

---

### 1. What is this?

The AI Workflow System is a powerful tool that uses a team of AI agents (Planner, Worker, and QA) to achieve a goal you provide. It breaks down your objective into smaller steps, executes them one by one, and checks its work along the way, correcting course as needed. This allows it to handle much more complex tasks than a simple single-prompt request.

---

### 2. Getting Started: Your First Workflow

#### Step 1: Configure Your LLM Provider
Before you can run a workflow, you need to tell the system which Large Language Model (LLM) to use.

*   Click the **Settings icon (⚙️)** in the top-right corner.
*   Select your desired LLM provider from the list on the left (e.g., Google, OpenAI, Ollama).
*   Fill in the required information. This typically includes an **API Key** and a **Model Name**. For local providers like Ollama, you may need to provide an **Endpoint URL**.
*   Use the **"Test Connection"** button to ensure your settings are correct. You should see a green checkmark if the connection is successful.
*   Your settings are saved automatically.

#### Step 2: Define Your Goal
In the main input area, describe what you want the AI to do. For best results, be clear and specific.

*   **Good example:** "Analyze the provided JSON data of user feedback, identify the top 3 most common complaints, and generate a summary report in Markdown format."
*   **Vague (but still works!):** "Improve our system's performance." The AI will attempt to create a plan to investigate and suggest improvements.

#### Step 3: Choose Your Mode
You can control the level of autonomy the AI has.

*   **Auto Mode (Default):** The AI operates completely autonomously. It will plan, execute, and review without user intervention until the goal is complete or it gets stuck. This is best for well-defined tasks.
*   **Human-Guided Mode:** The AI will first generate a plan and then **pause for your approval**. This gives you a chance to review the proposed steps. If you approve, the AI will proceed with execution. If you don't, you can go back and refine your goal. This mode is ideal for complex or ambiguous tasks where you want to ensure the AI is on the right track before it begins.

#### Step 4: Run the Workflow
Click the **"Run Workflow"** button. The system will now begin its Planner -> Worker -> QA loop. You can watch its progress in the results panel below.

---

### 3. Advanced Inputs

You can provide more than just a goal to the workflow.

#### Upload Knowledge (RAG)
Use the **"Upload Knowledge"** button to provide a text file (\`.txt\`, \`.md\`) as a context document. The AI can then search this document for specific information it needs to complete your goal.

*   **When to use it:** This is extremely useful when your task requires knowledge from private documents, reports, or specific data that the LLM wouldn't otherwise have access to. For example, you could upload a technical specification and ask the AI to write user documentation based on it.

#### Run from File
Use the **"Run from File"** button to start a workflow from a previously saved \`workflow-state.json\` file. This allows you to re-run or inspect a complex workflow without having to re-enter the goal and settings.

---

### 4. Understanding the Interface

Once a workflow is running or complete, the results area will populate with detailed information.

*   **Plan Sidebar:** On the left, you'll see the execution plan generated by the Planner. The current step is highlighted, allowing you to track progress in real-time.
*   **User-facing summary:** A brief, plain-language summary of the outcome or the current state of the workflow.
*   **Results Tabs:**
    *   **Result:** This tab shows the primary deliverable of the workflow—a comprehensive \`README.md\` file generated by the QA agent upon completion.
    *   **Support:** This tab lists all the individual files and assets (\`artifacts\`) created during the workflow, such as source code files, data files, or intermediate notes. You can download each file individually or all of them together as a \`.zip\` archive.
    *   **Run Log:** A detailed, step-by-step log of every action taken by the Planner, Worker, and QA agents. This is useful for understanding the AI's "thought process."
    *   **JSON State:** The raw, complete data object that represents the final state of the workflow. This is useful for debugging and for using with the "Run from File" feature.

---

### 5. Supported LLM Providers

*   **Google:** Uses the API key provided by the execution environment. No special configuration is needed.
*   **OpenAI / Claude / OpenRouter:** Require an API key and the specific model name you wish to use.
*   **Ollama:** Designed for running local models. Requires the model name (e.g., \`llama3\`) and the URL of your Ollama server (defaults to \`http://localhost:11434\`).

---

### 6. Security

Your API keys are sensitive. This application encrypts them using the browser's native Web Crypto API before saving them to your browser's local storage. They are never stored in plaintext.

---

### 7. Troubleshooting

*   **Connection Error:** If a "Test Connection" fails, double-check your API Key and Endpoint URL. Ensure there are no extra spaces or typos.
*   **Model Returned Invalid Response:** This can sometimes happen if the LLM produces a malformed JSON object. Simply try running the workflow again. If the problem persists, try a different model or simplify your goal.
*   **Run System Diagnostics:** In the **Settings** modal, you can find a **"Run All Tests"** button. This runs a series of internal checks to make sure the application's core logic is functioning correctly. If you're encountering persistent strange behavior, running these tests can help identify if the issue is with the application itself.

---

### 8. Programmatic Usage (API)

While the system does not expose a traditional REST API, you can trigger workflows programmatically by crafting a JSON file and using the **"Run from File"** feature. This provides a powerful way to integrate the workflow system into other scripts or processes.

#### API Format
The input must be a JSON file containing at least a \`goal\`. You can optionally specify \`maxIterations\`.

*   \`\`\`json
    {
      "goal": "Your detailed objective here.",
      "maxIterations": 50
    }
    \`\`\`

#### Example
Here is a complete example file, which you could save as \`my-workflow.json\`:

*   \`\`\`json
    {
      "goal": "Generate a Python script that analyzes a CSV file named 'sales_data.csv'. The script should calculate the total sales per product category and output a new CSV file named 'summary.csv'.",
      "maxIterations": 25
    }
    \`\`\`

#### How to Use
*   Create a \`.json\` file with the content structured as shown above.
*   In the application, click the **"Run from File"** button.
*   Select your JSON file. The workflow will start immediately using the goal and parameters you defined.
`;